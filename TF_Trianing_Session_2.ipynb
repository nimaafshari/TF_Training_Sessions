{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_Trianing_Session_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimaafshari/TF_Training_Sessions/blob/main/TF_Trianing_Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVhRb5DCh_Na"
      },
      "source": [
        "## **Session 2: Binary and Multi-class Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXA5poy7iLfv"
      },
      "source": [
        "This notebook walks through the implementation of binary and multi-class classification in Tensorflow (TF).\n",
        "\n",
        "Apart from the different network structures which the problem might have, the key difference between binary and multiclass classification is the final layer activation function. In binary classification we usually use a sigmoid activation function and for multiclass we typically use softmax. \n",
        "\n",
        "In this example we will train a multiclass classification problem using TF for greyscale images of handwritten 0-9 digits. \n",
        "\n",
        "**Agenda**\n",
        "\n",
        "1. Binary Classification for detecting 0 and 9 handwritten digits\n",
        "\n",
        "2. Multiclass classification for detecting 0 to 9 handwritten digits\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHbTURj0kf3I"
      },
      "source": [
        "\n",
        "First we should import the packages which we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLskCTZJRKbI"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Markdown\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a8H8qYGLe5N"
      },
      "source": [
        "The MNIST database of handwritten digits, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. \n",
        "\n",
        "The digits have already been size-normalized and centered in a fixed-size image. For the binary classification task we will filter the images to only those for 0 and 9 and we will then assign the labels False and True to them. \n",
        "\n",
        "For the multiclass section we will create a classification for all numbers (0-9) individually.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEAuqQ5pf6Tx"
      },
      "source": [
        "**1. Binary Classification**\n",
        "\n",
        "Here we prepare a function to filter the original data to have only 0 and 9 in our dataset and will try to predict only these 2 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG6dBWL9dfAn"
      },
      "source": [
        "def filter_09(x, y):\n",
        "    keep = (y == 0) | (y == 9)\n",
        "    x, y = x[keep], y[keep]\n",
        "    y = (y == 9)\n",
        "    return x,y"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY2bTcQMp7Ta"
      },
      "source": [
        "The MNIST dataset is available in the tensorflow keras package. First, we will load the dataset and then filter it to only the images of 0 and 9.  We can then check the size of the resulting training and test datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAXEifV6gYly",
        "outputId": "31d6362c-7c52-4428-cbe2-5d962e72005f"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "training_images, training_labels = filter_09(training_images, training_labels)\n",
        "test_images, test_labels = filter_09(test_images, test_labels)\n",
        "\n",
        "print(\"Number of filtered training examples:\", len(training_images))\n",
        "print(\"Number of filtered test examples:\", len(test_images))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Number of filtered training examples: 11872\n",
            "Number of filtered test examples: 1989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpv9AuUgg6Cv"
      },
      "source": [
        "Looking at some of the individual images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "8ZFtXNwagitQ",
        "outputId": "1ba21f69-76c6-455b-e70c-07efbbcb0cf9"
      },
      "source": [
        "index = 11\n",
        "\n",
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(training_images[index,:,:])\n",
        "display(Markdown(f'#<strong>Label:  {training_labels[index]}</strong><br/><br/>'))\n",
        "print(training_images[index,:,:],'\\n\\n')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Label:  False</strong><br/><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  46 105 254 254 254 254 255 239  41   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  37 118 222 254 253 253 253 253 253 253 211  54   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  14 200 253 253 254 253 253 253 253 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  16 160 236 253 253 253 254 253 253 246 229 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  99 253 253 253 253 253 254 253 253 213  99 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  25 194 253 253 253 253 131  97 169 253  93  99 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 206 253 253 251 233 127   9   0  18  38   3  15 171 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  55 240 253 253 233   0   0   0   0   0   0   0  31 186 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 176 253 253 253 127   0   0   0   0   0   0   0  99 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 176 253 253 131   9   0   0   0   0   0   0   0  99 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0 119 254 254 232  75   0   0   0   0   0   0   0   0   0 158 254 254 117   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 154   0   0   0   0   0   0   0   0   0   0 156 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 154   0   0   0   0   0   0   0   0   0   0 156 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0  46 222 253 253 154   0   0   0   0   0   0   0   0   7 116 246 253 180   9   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 154   0   0   0   0   0   0   0   0 116 253 253 253 174   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 154   0   0   0   0   0   0   0 110 246 253 253 240  67   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 238 215  49  20  20  20  66 215 241 253 245 233  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  82 229 253 253 253 253 253 253 253 254 253 253 240 107   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 176 253 253 253 253 253 253 253 254 253 253 108   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  40 239 253 253 253 253 253 253 254 161  57   4   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdz8hz6arYjp"
      },
      "source": [
        "It is a good practice to normalise the data whenever we use optimization algorithms. This will let the algorithm work more efficiently and converge faster. An easy method of normalization is just dividing by the maximum of the dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvc_15SlrcTC"
      },
      "source": [
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "training_images, test_images = training_images[..., np.newaxis]/255.0, test_images[..., np.newaxis]/255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kDoOrX_rhM_"
      },
      "source": [
        "Next we create, compile and train model in the TF. \n",
        "\n",
        "Note that these steps are completely specific to the problem we are trying to solve. For example here we want to use a Dense Layer in the model. As the input is in 2 dimensions (28*28) we should first convert that to 1-D using a flatten layer. \n",
        "\n",
        "Also for the last layer of the binary classification model we will use 1 neuron, with a sigmoid activation function. \n",
        "\n",
        "Although choosing (or tuning) the specific optimizers and loss functions is out of the scope of this training session, we will consider a trial and error approach to get the best for the problem we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB8PlD3Yg89m",
        "outputId": "0e4c29f0-07d5-4802-e1fb-0050319b9255"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation='relu'), \n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5, validation_data = (test_images, test_labels))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "371/371 [==============================] - 2s 4ms/step - loss: 0.0739 - accuracy: 0.9788 - val_loss: 0.0182 - val_accuracy: 0.9950\n",
            "Epoch 2/5\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0176 - val_accuracy: 0.9955\n",
            "Epoch 3/5\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0195 - val_accuracy: 0.9935\n",
            "Epoch 4/5\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0180 - val_accuracy: 0.9960\n",
            "Epoch 5/5\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0128 - val_accuracy: 0.9975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1375b8b810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib7zHY6RsiF-"
      },
      "source": [
        "Now let's test some predictions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "lagCZyx9iF0x",
        "outputId": "a4b35de4-119a-409f-8566-628ffe569a25"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "index = 16\n",
        "print(classifications[index])\n",
        "display(Markdown(f'#<strong>Predicted Label:  {np.round(classifications[index])}</strong><br/>'))\n",
        "display(Markdown(f'#<strong>Actual Label:  {test_labels[index]}</strong><br/>'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.999995]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Predicted Label:  [1.]</strong><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Actual Label:  True</strong><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgrjKsUWs5V5"
      },
      "source": [
        "Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDN1R7zIs48b",
        "outputId": "ec0b576d-8bd8-4e95-d92d-90973d340387"
      },
      "source": [
        "tf.math.confusion_matrix(test_labels, classifications)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[980,   0],\n",
              "       [629, 380]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx8hic8MpAXW"
      },
      "source": [
        "**2. Multi-class Classification:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7CXbwNFtc1D"
      },
      "source": [
        "Loading the same dataset but this time without filtering, so it has all the 0-9 numbers in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSoC65vtKmRX"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nXUlwiBREHx"
      },
      "source": [
        "Let's take a look at what we get - first looking at the dataset shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pXiF20uRDkP",
        "outputId": "1a2912d3-305a-42c6-e54c-54dd92b51610"
      },
      "source": [
        "print(f'''\n",
        "Shape of train data:  {training_images.shape}\n",
        "\n",
        "Shape of train_label data:  {training_labels.shape}\n",
        "\n",
        "Shape of test data:  {test_images.shape}\n",
        "\n",
        "Shape of test_label data:  {test_labels.shape}\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Shape of train data:  (60000, 28, 28)\n",
            "\n",
            "Shape of train_label data:  (60000,)\n",
            "\n",
            "Shape of test data:  (10000, 28, 28)\n",
            "\n",
            "Shape of test_label data:  (10000,)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDbVkzxeU0Xf"
      },
      "source": [
        "Now looking at some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "Uswd5q9ZS6ul",
        "outputId": "548b5452-3ca6-4b1b-f104-e47fabc066fc"
      },
      "source": [
        "index = 10\n",
        "\n",
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(training_images[index,:,:])\n",
        "display(Markdown(f'#<strong>Label:  {training_labels[index]}</strong><br/><br/>'))\n",
        "print(training_images[index,:,:],'\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Label:  3</strong><br/><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  42 118 219 166 118 118   6   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 103 242 254 254 254 254 254  66   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  18 232 254 254 254 254 254 238  70   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104 244 254 224 254 254 254 141   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 207 254 210 254 254 254  34   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  84 206 254 254 254 254  41   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  24 209 254 254 254 171   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  91 137 253 254 254 254 112   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  40 214 250 254 254 254 254 254  34   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  81 247 254 254 254 254 254 254 146   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 110 246 254 254 254 254 254 171   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  73  89  89  93 240 254 171   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 128 254 219  31   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7 254 254 214  28   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 138 254 254 116   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  19 177  90   0   0   0   0   0  25 240 254 254  34   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 164 254 215  63  36   0  51  89 206 254 254 139   8   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  57 197 254 254 222 180 241 254 254 253 213  11   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 140 105 254 254 254 254 254 254 236   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   7 117 117 165 254 254 239  50   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSh0bxUBLXQm"
      },
      "source": [
        "The first step in ML projects is to split the train/test portions. Fortunately, the MNIST dataset is already splitted for us (this helps researchers  to benchmark and compare models). \n",
        "\n",
        "The next step is to normalize the data. This step is not tied to only ML, it is an statistical necessity whenever use optimization methods to make all input data comparable to eachother (Various techniques can produce different results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So6FVC_OLWue"
      },
      "source": [
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "training_images, test_images = training_images[..., np.newaxis]/255.0, test_images[..., np.newaxis]/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hp_afH9Zq7N"
      },
      "source": [
        "Now let's create our neural network. \n",
        "\n",
        "Here our input is 2-dimensional. Convolutionals can handle multiple dimensions directly and usually we use them for multi-dimesional projects.  However, for this training session we will convert that to 1-dimension using the flatten layer and then create the remaining part of the neural network for a (28*28 = 784) vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVfRT49bXpce",
        "outputId": "6d056a2d-b5e2-442e-a1bd-ae6bece45406"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation='relu'), \n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4241 - accuracy: 0.8804\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1229 - accuracy: 0.9650\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0824 - accuracy: 0.9762\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0615 - accuracy: 0.9810\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0448 - accuracy: 0.9867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f7191c410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrzdImROdKh1"
      },
      "source": [
        "Evaluate the model using the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0YET1VlcYKG",
        "outputId": "93c9cbb9-11ab-42df-e80b-abe27ee25640"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06712546199560165, 0.9789999723434448]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDdKTIxadYjd"
      },
      "source": [
        "Looking at some of the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "wz6y5LV1dO0Q",
        "outputId": "486c1267-a4cc-4d53-b4c8-5620efe6c9c7"
      },
      "source": [
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "index = 4\n",
        "print(classifications[index])\n",
        "display(Markdown(f'#<strong>Predicted Label:  {np.argmax(classifications[index])}</strong><br/>'))\n",
        "display(Markdown(f'#<strong>Actual Label:  {test_labels[index]}</strong><br/>'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.8707333e-07 8.8003658e-09 4.2051499e-07 9.3063752e-09 9.9806291e-01 4.6708712e-09 1.2393573e-07 1.1552711e-05 3.6809831e-07 1.9243339e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Predicted Label:  4</strong><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Actual Label:  4</strong><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In33KAgTiru5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}