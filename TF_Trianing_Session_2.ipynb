{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_Trianing_Session_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUy2BPaztlDhxJCcpGsLgB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimaafshari/TF_Training_Sessions/blob/main/TF_Trianing_Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLskCTZJRKbI"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Markdown\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rNqEcOXLPW5"
      },
      "source": [
        "Binary and multiclass classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a8H8qYGLe5N"
      },
      "source": [
        "Multi-class classification:\n",
        "Apart from the different network structures which the problem might have, the only difference between binary and multiclass classification is final layer activation function. In binary classification we usually use a sigmoid activation function and in multiclass one softmax is the proper choice. In this example we train a multiclass classification problem using TF for a monochrome image 0-9 number dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSoC65vtKmRX"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nXUlwiBREHx"
      },
      "source": [
        "Let's take a look at what we got. First looking at the dataset shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pXiF20uRDkP",
        "outputId": "b415a6c9-84f7-4c85-ca42-5fa43da3051b"
      },
      "source": [
        "print(f'''\n",
        "Shape of train data:  {training_images.shape}\n",
        "\n",
        "Shape of train_label data:  {training_labels.shape}\n",
        "\n",
        "Shape of test data:  {test_images.shape}\n",
        "\n",
        "Shape of test_label data:  {test_labels.shape}\n",
        "''')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Shape of train data:  (60000, 28, 28)\n",
            "\n",
            "Shape of train_label data:  (60000,)\n",
            "\n",
            "Shape of test data:  (10000, 28, 28)\n",
            "\n",
            "Shape of test_label data:  (10000,)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDbVkzxeU0Xf"
      },
      "source": [
        "Let's look at some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "Uswd5q9ZS6ul",
        "outputId": "d76a76ca-1c6d-497a-f18a-1f4878ecdb2d"
      },
      "source": [
        "index = 10\n",
        "\n",
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(training_images[index,:,:])\n",
        "display(Markdown(f'#<strong>Label:  {training_labels[index]}</strong><br/><br/>'))\n",
        "print(training_images[index,:,:],'\\n\\n')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Label:  3</strong><br/><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  42 118 219 166 118 118   6   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 103 242 254 254 254 254 254  66   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  18 232 254 254 254 254 254 238  70   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104 244 254 224 254 254 254 141   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 207 254 210 254 254 254  34   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  84 206 254 254 254 254  41   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  24 209 254 254 254 171   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  91 137 253 254 254 254 112   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  40 214 250 254 254 254 254 254  34   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  81 247 254 254 254 254 254 254 146   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 110 246 254 254 254 254 254 171   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  73  89  89  93 240 254 171   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 128 254 219  31   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7 254 254 214  28   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 138 254 254 116   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  19 177  90   0   0   0   0   0  25 240 254 254  34   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 164 254 215  63  36   0  51  89 206 254 254 139   8   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  57 197 254 254 222 180 241 254 254 253 213  11   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 140 105 254 254 254 254 254 254 236   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   7 117 117 165 254 254 239  50   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN3UlEQVR4nO3df4wU93nH8c8DnMEcuAXTUIKx+SEam8YtqS/EclDlxopFrMQ4iuQGVSmtkM9NgpsoNK3lVrLlf2o5tWlSxbGOmIa0jn9IYJlWqA0mUd0oMfKZUH7ZBkyxwuUMdWlqoOL30z9uiA64+e4xM7uz3PN+SavdnWdn5/Gaz83ufHf2a+4uACPfqLobANAahB0IgrADQRB2IAjCDgQxppUbu8LG+jh1tnKTQCjHdUwn/YQNVSsVdjNbJOnrkkZL+ra7P5J6/Dh16iN2W5lNAkjY7Jtya4XfxpvZaEnflPQJSfMkLTGzeUWfD0BzlfnMvkDSXnff5+4nJT0raXE1bQGoWpmwT5f0s0H3D2TLzmNm3WbWa2a9p3SixOYAlNH0o/Hu3uPuXe7e1aGxzd4cgBxlwt4nacag+9dkywC0oTJhf1XSXDObZWZXSPqspPXVtAWgaoWH3tz9tJktl/SvGhh6W+3uOyvrDEClSo2zu/sGSRsq6gVAE/F1WSAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCaOmUzWiSm38rt/Sfd6anyH7wM88n64/vTs+6e2T71cl6ypyHf5qsnz1+vPBz42Ls2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZLwN999+SrG/4wqO5tWvHTCi17T+4KT0Or5uKP/fC1+5N1jvXbi7+5LhIqbCb2X5JRySdkXTa3buqaApA9arYs/+eu79bwfMAaCI+swNBlA27S/q+mb1mZt1DPcDMus2s18x6T+lEyc0BKKrs2/iF7t5nZu+TtNHM3nD3lwc/wN17JPVI0lU22UtuD0BBpfbs7t6XXR+S9IKkBVU0BaB6hcNuZp1mNvHcbUm3S9pRVWMAqlXmbfxUSS+Y2bnn+Z67/0slXeE8163Zl6z/vPvK3Nq1bfxNilWPrUzWl435SrI+8blXqmxnxCv8T8Hd90n67Qp7AdBEDL0BQRB2IAjCDgRB2IEgCDsQRBsPzOCc0/3vJOvLVt2XW3vp8/mnv0rStAanwK4/Nj5Zv7Pz/5L1lBuuSD93/8dPJ+sTnyu86ZDYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyzjwDX/PWPc2t/vyT9W88PTHkzWd974tfTG+9Mn35bxvXfOJqsn23alkcm9uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7CPcur/7WLJ+9j5L1v9qyhtVtnNJzo7rqG3bIxF7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2Ee7qVT9J1n/y0geS9a/906lk/auT37rknobr6MPHkvUJi5q26RGp4Z7dzFab2SEz2zFo2WQz22hme7LrSc1tE0BZw3kb/x1JF/4NvV/SJnefK2lTdh9AG2sYdnd/WdLhCxYvlrQmu71G0l0V9wWgYkU/s0919/7s9juSpuY90My6JXVL0jil5/YC0Dylj8a7u0vyRL3H3bvcvatDY8tuDkBBRcN+0MymSVJ2fai6lgA0Q9Gwr5e0NLu9VNKL1bQDoFkafmY3s2ck3SppipkdkPSgpEckPW9myyS9LenuZjaJ4g4tvyVZ/8UH03Ogr5/0QoMtNO97WYdfSf9m/QQ17zfrR6KGYXf3JTml2yruBUAT8XVZIAjCDgRB2IEgCDsQBGEHguAU18uAffjGZP2uNT/Irf3hVX+bXHf8qCsabL2+/cHMdReeknE+pmy+NOzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtkvA/9944Rk/fcn7smtjR91+f4U2Jsr0r3PXZos4wLs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZLwOTV6enXb7lmj/Lrf37PV9LrjtldGehnlph2tRf1N3CiMKeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJx9BLj24R/n1j61d0Vy3eO/Wu7vvTf4F7R2xaO5tTkd6fP0Ua2G/6fNbLWZHTKzHYOWPWRmfWa2Nbvc0dw2AZQ1nD/r35G0aIjlK919fnbZUG1bAKrWMOzu/rKk9Dw8ANpemQ9sy81sW/Y2f1Leg8ys28x6zaz3lE6U2ByAMoqG/VuS5kiaL6lf0mN5D3T3HnfvcveuDo0tuDkAZRUKu7sfdPcz7n5W0ipJC6ptC0DVCoXdzKYNuvtpSTvyHgugPTQcZzezZyTdKmmKmR2Q9KCkW81sviSXtF/SvU3sESVc9b1X0vWyGzBLlm+fnX+u/Vt3P5lc9wuz/i1Zf3rebcn6mV27k/VoGobd3ZcMsfipJvQCoIn4uiwQBGEHgiDsQBCEHQiCsANBcIorShl15ZXJeqPhtZQjZ8alH3D6TOHnjog9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTg7Snlj5W82eET+z1w3snLdncn6zN3pqaxxPvbsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+zDNGb6+3NrJ787Ornuu+tmJOvv+2bxsehmGzN7ZrL+0qKVDZ6h+LTMs5//n2T9bOFnjok9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTj7MP38ifzJjX96w7PJdXuW54/RS9I/9n0yWe/cfzRZP7t1V27t9MduSq57+Pqxyfpn/uQHyfqcjuLj6LP++Z5k/fq38v+7cOka7tnNbIaZ/dDMdpnZTjP7UrZ8spltNLM92fWk5rcLoKjhvI0/LWmFu8+TdLOkL5rZPEn3S9rk7nMlbcruA2hTDcPu7v3uviW7fUTS65KmS1osaU32sDWS7mpWkwDKu6TP7GY2U9KHJG2WNNXd+7PSO5Km5qzTLalbksZpfNE+AZQ07KPxZjZB0lpJX3b39wbX3N0l+VDruXuPu3e5e1eH0geDADTPsMJuZh0aCPrT7r4uW3zQzKZl9WmSDjWnRQBVaPg23sxM0lOSXnf3xweV1ktaKumR7PrFpnTYJn7lyYm5tT+d/uHkut94/6vJevcTPcn62qP5w36S9FTfwtzak7O/nlx3VomhM0k64+kTTZ/83+tyazf8+e70cx87VqgnDG04n9k/Kulzkrab2dZs2QMaCPnzZrZM0tuS7m5OiwCq0DDs7v4jSZZTvq3adgA0C1+XBYIg7EAQhB0IgrADQRB2IAgb+PJba1xlk/0jNvIO4O9elR5nH7+vI1nfed8TVbbTUttOHk/Wvzrz5hZ1Akna7Jv0nh8ecvSMPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBMFPSVfgN+5Jn68+anz657g+MOHzpbbfeePh3NqWrudKPffuU+lzyr/yx/cl66O1pdT2UR327EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOezAyMI57MDIOxAFIQdCIKwA0EQdiAIwg4EQdiBIBqG3cxmmNkPzWyXme00sy9lyx8ysz4z25pd7mh+uwCKGs6PV5yWtMLdt5jZREmvmdnGrLbS3f+mee0BqMpw5mfvl9Sf3T5iZq9Lmt7sxgBU65I+s5vZTEkfkrQ5W7TczLaZ2Wozm5SzTreZ9ZpZ7ymdKNUsgOKGHXYzmyBpraQvu/t7kr4laY6k+RrY8z821Hru3uPuXe7e1aGxFbQMoIhhhd3MOjQQ9KfdfZ0kuftBdz/j7mclrZK0oHltAihrOEfjTdJTkl5398cHLZ826GGflrSj+vYAVGU4R+M/Kulzkrab2dZs2QOSlpjZfEkuab+ke5vSIYBKDOdo/I8kDXV+7Ibq2wHQLHyDDgiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EERLp2w2s/+S9PagRVMkvduyBi5Nu/bWrn1J9FZUlb1d5+6/NlShpWG/aONmve7eVVsDCe3aW7v2JdFbUa3qjbfxQBCEHQii7rD31Lz9lHbtrV37kuitqJb0VutndgCtU/eeHUCLEHYgiFrCbmaLzOxNM9trZvfX0UMeM9tvZtuzaah7a+5ltZkdMrMdg5ZNNrONZrYnux5yjr2aemuLabwT04zX+trVPf15yz+zm9loSbslfVzSAUmvSlri7rta2kgOM9svqcvda/8Chpn9rqSjkr7r7h/Mlj0q6bC7P5L9oZzk7n/RJr09JOlo3dN4Z7MVTRs8zbikuyT9kWp87RJ93a0WvG517NkXSNrr7vvc/aSkZyUtrqGPtufuL0s6fMHixZLWZLfXaOAfS8vl9NYW3L3f3bdkt49IOjfNeK2vXaKvlqgj7NMl/WzQ/QNqr/neXdL3zew1M+uuu5khTHX3/uz2O5Km1tnMEBpO491KF0wz3javXZHpz8viAN3FFrr770j6hKQvZm9X25IPfAZrp7HTYU3j3SpDTDP+S3W+dkWnPy+rjrD3SZox6P412bK24O592fUhSS+o/aaiPnhuBt3s+lDN/fxSO03jPdQ042qD167O6c/rCPurkuaa2Swzu0LSZyWtr6GPi5hZZ3bgRGbWKel2td9U1OslLc1uL5X0Yo29nKddpvHOm2ZcNb92tU9/7u4tv0i6QwNH5N+S9Jd19JDT12xJ/5Fddtbdm6RnNPC27pQGjm0sk3S1pE2S9kh6SdLkNurtHyRtl7RNA8GaVlNvCzXwFn2bpK3Z5Y66X7tEXy153fi6LBAEB+iAIAg7EARhB4Ig7EAQhB0IgrADQRB2IIj/B9j5Aat0flZ6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSh0bxUBLXQm"
      },
      "source": [
        "The first step in ML projects is to split the train/test portions. Fortunately, the mnist is splitted to be a better benchmark to compare the models of different researchers. The next step is to normalize the data. This step is not tied to only ML, it is an statistical necessity whenever use optimization methods to make all input data comparable to eachother (Various techniques can produce different results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So6FVC_OLWue"
      },
      "source": [
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "training_images, test_images = training_images[..., np.newaxis]/255.0, test_images[..., np.newaxis]/255.0"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hp_afH9Zq7N"
      },
      "source": [
        "Now let's create our neural network. Unless previous session example here our input is 2-dimensional. Cconvolutionals can handle multidimensions directly and usually we use them for multi-dimesional projects. But for the purpose of this training we convert that to 1-dimensional using the flatten layer and then create our the remaining part of the neural network for a (28*28 = 784) vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVfRT49bXpce",
        "outputId": "82ffb565-4102-4e04-f2e3-9aab1fee17e5"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation='relu'), \n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4343 - accuracy: 0.8770\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1221 - accuracy: 0.9630\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0808 - accuracy: 0.9758\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0575 - accuracy: 0.9837\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0443 - accuracy: 0.9863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f66d3bf4a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrzdImROdKh1"
      },
      "source": [
        "Evaluate the model using the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0YET1VlcYKG",
        "outputId": "6a4808b9-6d8f-434c-8f95-edc7f43ebdba"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.0797 - accuracy: 0.9760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07968883961439133, 0.9760000109672546]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDdKTIxadYjd"
      },
      "source": [
        "Looking at some of the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "wz6y5LV1dO0Q",
        "outputId": "1029ba05-9cc3-468e-cbfa-07e89c579981"
      },
      "source": [
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "index = 4\n",
        "print(classifications[index])\n",
        "display(Markdown(f'#<strong>Predicted Label:  {np.argmax(classifications[index])}</strong><br/>'))\n",
        "display(Markdown(f'#<strong>Actual Label:  {test_labels[index]}</strong><br/>'))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3729018e-07 6.8371964e-10 1.9119764e-06 8.4839179e-08 9.9812537e-01 1.0393331e-06 3.9120818e-07 1.5104358e-05 8.0365198e-06 1.8478929e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Predicted Label:  4</strong><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Actual Label:  4</strong><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEAuqQ5pf6Tx"
      },
      "source": [
        "**Binary Classification**\n",
        "\n",
        "Here we filter the original data to have only 0 and 9 in our dataset and will try to predict only those 2 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG6dBWL9dfAn"
      },
      "source": [
        "def filter_09(x, y):\n",
        "    keep = (y == 0) | (y == 9)\n",
        "    x, y = x[keep], y[keep]\n",
        "    y = (y == 9)\n",
        "    return x,y"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAXEifV6gYly",
        "outputId": "b0d8deef-a9c9-4537-db14-2370c312c21d"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "training_images, training_labels = filter_09(training_images, training_labels)\n",
        "test_images, test_labels = filter_09(test_images, test_labels)\n",
        "\n",
        "print(\"Number of filtered training examples:\", len(training_images))\n",
        "print(\"Number of filtered test examples:\", len(test_images))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of filtered training examples: 11872\n",
            "Number of filtered test examples: 1989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpv9AuUgg6Cv"
      },
      "source": [
        "Looking at some of those"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "8ZFtXNwagitQ",
        "outputId": "8ebbde38-7391-4f96-951e-41f8fbce503d"
      },
      "source": [
        "index = 11\n",
        "\n",
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(training_images[index,:,:])\n",
        "display(Markdown(f'#<strong>Label:  {training_labels[index]}</strong><br/><br/>'))\n",
        "print(training_images[index,:,:],'\\n\\n')\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Label:  False</strong><br/><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  46 105 254 254 254 254 255 239  41   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  37 118 222 254 253 253 253 253 253 253 211  54   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  14 200 253 253 254 253 253 253 253 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  16 160 236 253 253 253 254 253 253 246 229 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  99 253 253 253 253 253 254 253 253 213  99 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  25 194 253 253 253 253 131  97 169 253  93  99 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 206 253 253 251 233 127   9   0  18  38   3  15 171 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  55 240 253 253 233   0   0   0   0   0   0   0  31 186 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 176 253 253 253 127   0   0   0   0   0   0   0  99 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 176 253 253 131   9   0   0   0   0   0   0   0  99 253 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0 119 254 254 232  75   0   0   0   0   0   0   0   0   0 158 254 254 117   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 154   0   0   0   0   0   0   0   0   0   0 156 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 154   0   0   0   0   0   0   0   0   0   0 156 253 253 116   0   0   0   0   0]\n",
            " [  0   0   0   0  46 222 253 253 154   0   0   0   0   0   0   0   0   7 116 246 253 180   9   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 154   0   0   0   0   0   0   0   0 116 253 253 253 174   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 154   0   0   0   0   0   0   0 110 246 253 253 240  67   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 118 253 253 238 215  49  20  20  20  66 215 241 253 245 233  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  82 229 253 253 253 253 253 253 253 254 253 253 240 107   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 176 253 253 253 253 253 253 253 254 253 253 108   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  40 239 253 253 253 253 253 253 254 161  57   4   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB8PlD3Yg89m",
        "outputId": "6119a5e1-3d74-4a79-83f6-4c0a27a134bb"
      },
      "source": [
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "training_images, test_images = training_images[..., np.newaxis]/255.0, test_images[..., np.newaxis]/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation='relu'), \n",
        "                                    tf.keras.layers.Dense(2, activation='sigmoid')])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5, validation_data = (test_images, test_labels))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "371/371 [==============================] - 1s 3ms/step - loss: 0.0669 - accuracy: 0.9798 - val_loss: 0.0257 - val_accuracy: 0.9915\n",
            "Epoch 2/5\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.0139 - accuracy: 0.9966 - val_loss: 0.0237 - val_accuracy: 0.9930\n",
            "Epoch 3/5\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0189 - val_accuracy: 0.9945\n",
            "Epoch 4/5\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0147 - val_accuracy: 0.9950\n",
            "Epoch 5/5\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0142 - val_accuracy: 0.9975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f66bf3fcd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "lagCZyx9iF0x",
        "outputId": "bc347edb-0be1-4833-f528-30998f93883f"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "index = 10\n",
        "print(classifications[index])\n",
        "display(Markdown(f'#<strong>Predicted Label:  {np.argmax(classifications[index])}</strong><br/>'))\n",
        "display(Markdown(f'#<strong>Actual Label:  {test_labels[index]}</strong><br/>'))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9771075  0.01614317]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Predicted Label:  0</strong><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#<strong>Actual Label:  False</strong><br/>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In33KAgTiru5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}